{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Landers125/AI-Music-Project/blob/master/1b_Finetuned_v1_4_20_(Community_models)_for_Free_users.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNfCjHdZ0PU7"
      },
      "source": [
        "# JukeboxAI: 1b_Finetuned v1.4.1\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This is a notebook to which people submitted their own jukebox models that aim to perform better at a specific task than the standard out-of-the-box jukebox 1b_lyrics model.\n",
        "\n",
        "If you want to add your model in this notebook, you could send a private message to Pikachu ✓#5870 on discord or send your model in the jukebox server with an example.\n",
        "\n",
        "Some models do not have the abillity to generate music with **coherent** lyrics (NOLYRICS models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jsglkier2FPx"
      },
      "outputs": [],
      "source": [
        "#@title #Changelog\n",
        "#@markdown Open this cell to view all changelogs\n",
        "\n",
        "\n",
        "\n",
        "#CHANGELOG\n",
        "\n",
        "#11-01-2022 - Notebook made and now is ready to be released with 4 models, Weezer Blue Album (NOLYRICS), Weezer Blue Album, Ghost and S3rl. All made by Brocaloo\n",
        "\n",
        "\n",
        "#*CHANGELOG V1.0 - V1.1*\n",
        "\n",
        "#12-01-2022 | 1b_Finetuned V1.0 - Notebook's planned release date to be released to the public.\n",
        "\n",
        "#12-01-2022 | 1b_Finetuned V1.1 - Added 2 extra models (Ed sheeran, 2010s Raps) and a changelog to the notebook.\n",
        "\n",
        "#*CHANGELOG V1.2*\n",
        "\n",
        "# 13-01-2022 | 1b_Finetuned v1.2 - Notebook's release date moved to somewhere in the future.\n",
        "\n",
        "# 13-01-2022 | 1b_Finetuned v1.2 - Added an extra model (Katy Perry).\n",
        "\n",
        "#*CHANGELOG V1.2b-V1.2c*\n",
        "\n",
        "#14-01-2022 | 1b_finetuned V1.2b - \"Fixed\" bug where notebook runs out of ram in upsampling - [UPDATE] Didn't work\n",
        "\n",
        "#14-01-2022 | 1b_finetuned V1.2c - Actually fixed the bug where the notebook runs out of ram in upsampling - [UPDATE] I hate this ;-;\n",
        "\n",
        "#*CHANGELOG V1.3*\n",
        "\n",
        "#19-01-2022 | 1b_finetuned V1.3 - All fixes for upsampling did not work previously, using code from older notebook should help now.\n",
        "\n",
        "#*CHANGELOG V1.4 - V1.4.1*\n",
        "\n",
        "#22-01-2022 | 1b_finetuned V1.4 - Fixed google drive linking error when attempting to use normal drive linking code. (You can now link different accounts to one colab session.)\n",
        "\n",
        "#22-01-2022 | 1b_finetuned V1.4.1 - Tiny bug fixes to allow files to be saved on the google drive.\n",
        "\n",
        "#----------------------------\n",
        "                #############\n",
        "                #WE ARE HERE#\n",
        "                #############\n",
        "\n",
        "#@markdown *CHANGELOG V1.4.20*\n",
        "\n",
        "#@markdown 05-02-2022 | Added an extra model (Charlie Green, CG5). This model is still very early in training phase (hasn't even reached 10K steps yet) but it's worth adding it in as it will improve a lot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZAGS4j8u0gdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6798c1d5-7ffe-4e06-fcb1-614c17451ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-036395e2-00ff-9148-352e-8474ee82efef)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n"
          ]
        }
      ],
      "source": [
        "#@title Check your GPU *\n",
        "#@markdown Preferably you want to get the fastest GPU but in Colab free, you can only get the k80. Recently google added the T4 for free users again. Hoorayy!!!\n",
        "!nvidia-smi -L\n",
        "\n",
        "\n",
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!pip install gdown --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PUMnze1AUXCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927696e5-329c-430c-af23-9b7037514ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=17_VpUbdYXGi_OI-e74X0VYgW6rNm02Mu \n",
            "\n",
            "Succesfully downloaded the CG5-VeryEarly-Askejm+pikachu model.\n"
          ]
        }
      ],
      "source": [
        "##Some stuff to let google colab create its stuff I guess...\n",
        "\n",
        "#@title Select Artist\n",
        "lept_artist = \"CG5-VeryEarly-Askejm+pikachu\" #@param [\"2010sRap-NOLYRICS-memphis\", \"Weezer-Blue-Album-NOLYRICS-Broccaloo\", \"Ghost-NOLYRICS-Broccaloo\", \"S3rl-NOLYRICS-Broccaloo\", \"Weezer-Blue-Album-Broccaloo\", \"Ed-Sheeran-early-memphis+pikachu\", \"Katy-Perry-memphis\", \"CG5-VeryEarly-Askejm+pikachu\"]\n",
        "#@markdown Because this notebook relies on custom models created by the community, there aren't a lot of models.\n",
        "\n",
        "#@markdown Please note that the specific model chosen can either perform bad or very good, this entirely depends on how the model was fine-tuned and created. Also, models with the \"NOLYRICS\" in their name haven't been finetuned on lyrics, meaning they basically cannot generate music with **coherent** singing.\n",
        "\n",
        "#@markdown Most of the models should still be better at generating music in the style of artists they've been trained on specifically rather than the generic 1b_lyrics model. The custom models have also been trained with a lower batch size compared to 1b_lyrics.\n",
        "\n",
        "if lept_artist == \"2010sRap-NOLYRICS-memphis\":      ## I'm bad at python, don't judge me -w-\n",
        "  !gdown --id 1S0V971VthQeLt0lwbEaY_0I6Isi3rFYd\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "if lept_artist == \"Weezer-Blue-Album-NOLYRICS-Broccaloo\":   \n",
        "  !gdown --id 1-ES2M9XP_O2CC43RpUgFPIdJ0rhQtJ20\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "elif lept_artist == \"Weezer-Blue-Album-Broccaloo\":\n",
        "  !gdown --id 1GQsgIpSPckEre0GdINLAeFLHcA9v1udD\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "elif lept_artist == \"Ghost-NOLYRICS-Broccaloo\":\n",
        "  !gdown --id 1-K_s9BOIRt6h8pXO-DdRZula9_bU9IR6\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "elif lept_artist == \"S3rl-NOLYRICS-Broccaloo\":\n",
        "  !gdown --id 1-2e66lExjsZky3a0B2nPhkvyi0s9Lamg\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "elif lept_artist == \"Ed-Sheeran-memphis+pikachu\":\n",
        "  !gdown --id 1-D2rr0DFtLbuUHp6Z_NTPaHCRmySmuqO\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "elif lept_artist == \"Katy-Perry-memphis\":\n",
        "  !gdown --id 1oHnXHVaPIzUyAHqH-shm_5Iv2jLNa4ct\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "elif lept_artist == \"CG5-VeryEarly-Askejm+pikachu\":\n",
        "  !gdown --id 17_VpUbdYXGi_OI-e74X0VYgW6rNm02Mu\n",
        "  print(f\"Succesfully downloaded the {lept_artist} model.\")\n",
        "else:\n",
        "  print(\"Model isn't available or doesn't exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3jQqy8yvxzP"
      },
      "source": [
        "# Important.\n",
        "To make sure the notebook works, open the filebrowser and make sure that the file you've just downloaded says \"checkpoint.pth.tar\" (if you don't see it and you see a different file, hover over it and check if the size is about 5 gb). If the filename isn't named to that, change the filename to be that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAGS4aH_BPGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ca7410-ba11-4e44-ed41-2487679b9c2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.27-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "/content\n",
            "/content/gdrive\n",
            "/content\n",
            "/\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "#@title Connect drive *\n",
        "#@markdown Connect your drive to google colab to save your results.\n",
        "\n",
        "\n",
        "#@markdown ***This method works differently and takes longer to connect your drive but it allows you to connect your drive to different accounts.***\n",
        "\n",
        "#@markdown **PLEASE NOTE:** This cell will ask you to click on a link **twice**.\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/gdrive/MyDrive\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtK7KvgqCI-k"
      },
      "outputs": [],
      "source": [
        "#@title Define your parameters *\n",
        "\n",
        "# Stopped mid level = 2? use continue\n",
        "# Stopped mid level = 1 or 0? use upsample\n",
        "\n",
        "####################\n",
        "#Define your stuff!#\n",
        "####################\n",
        "\n",
        "\n",
        "lemode = 'ancestral'     # 'ancestral','primed','continue','cutcontinue','upsample'\n",
        "lemodel = 'custom'\n",
        "\n",
        "lecount = 8 \t              #I think you're only able to upsample your samples if you have 8 or less wavs, I'm not sure.\n",
        "lesample_length_in_seconds = 120\n",
        "lesampling_temperature = .98\n",
        "lehop = [1,1,.125]                 #default [.5,.5,.125], optimized [1,1,0.0625]\n",
        "\n",
        "lepath = '/content/gdrive/MyDrive/cg5aiprimed'\n",
        "\n",
        "leprompt_length_in_seconds=11  \n",
        "leaudio_file = '/content/gdrive/MyDrive/phoenix.wav'                    \n",
        "\n",
        "lecut = 70               # used only on cutcontinue\n",
        "transpose = [0,1,2]      # used only on cutcontinue [0,1,2] = default, ex [1,1,1] all samples are copied from item 1\n",
        "\n",
        "leexportlyrics = False\n",
        "leprogress = True\n",
        "leautorename = True\n",
        "\n",
        "leartist = \"unknown\" ##These don't matter as you're gonna be using a custom model.\n",
        "legenre = \"unknown\"\n",
        "lelyrics = \"\"\"I'll be your guardian, I'll be your friend\n",
        "I'll be your friend!\n",
        "Phoenix of the sea, swimmin' in the deep, subaquatically, ya, ya, ya!\n",
        "Healing is a breeze, understandably, can you feel the beat?, ya, ya, ya!\n",
        "I just wanna be free! Free to be, free to be me! (Yeah)\n",
        "I just wanna be free! Free to be, free to be me!\n",
        "Take me to the shore, so much to explore, it's all so great\n",
        "In that bucket o' yours, keep me safe and warm out in the rain\n",
        "Gonna be goin' back home, don't wanna be all alone\n",
        "Underwater galaxy, and it's all for me, yeah, yeah!\n",
        "Oh, my beloved, come, follow me\n",
        "Go with the motion, down the stream\n",
        "I'll be your guardian, I'll be your friend\n",
        "I'll be your friend!\n",
        "Phoenix of the sea, swimmin' in the deep, subaquatically, ya, ya, ya!\n",
        "Healin' is a breeze, understandably, can you feel the beat?, ya, ya, ya!\n",
        "I just wanna be free! Free to be, free to be me! (Ah! Yeah)\n",
        "I just wanna be free! (Ah!) Free to be, free to be me!\n",
        "Free to be, free to be me (an axolotl)\n",
        "Free to be, free to be me (oh God! Yeah!)\n",
        "Free to be, free to be me\n",
        "Free to be, free to be me\n",
        "\"\"\"\n",
        "\n",
        "lecustommodellyrics = False\n",
        "\n",
        "lechunk_size = 16 \n",
        "lemax_batch_size = 12\n",
        "lelower_batch_size = lecount\n",
        "lelower_level_chunk_size = lechunk_size * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-8cvPn3CO4s"
      },
      "source": [
        "# 1. Sample 👏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAGS4k1WCC_C",
        "outputId": "3e9f36d1-de5b-48d7-f2ae-92776db23f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/jukebox.git\n",
            "  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-79izejdd\n",
            "  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-79izejdd\n",
            "Collecting fire==0.1.3\n",
            "  Downloading fire-0.1.3.tar.gz (33 kB)\n",
            "Collecting tqdm==4.45.0\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from jukebox==1.0) (0.10.3.post1)\n",
            "Collecting unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 28.0 MB/s \n",
            "\u001b[?25hCollecting numba==0.48.0\n",
            "  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 63.9 MB/s \n",
            "\u001b[?25hCollecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 56.4 MB/s \n",
            "\u001b[?25hCollecting mpi4py>=3.0.0\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 49.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.1.3->jukebox==1.0) (1.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.2.2)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48.0->jukebox==1.0) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.21)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->jukebox==1.0) (3.1.0)\n",
            "Building wheels for collected packages: jukebox, fire, librosa, mpi4py\n",
            "  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jukebox: filename=jukebox-1.0-py3-none-any.whl size=197916 sha256=97bc498a35a051a2a94a2e716a2b620ee52edf80c2849f2ec99b584e4f09f4bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xl4rhdb7/wheels/d6/42/39/91f8a32505a445499702ae0f887769e6bb5030c42382d74ae0\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49719 sha256=ad969190d89ea72113f12c47930311d3c1a20ea59cfc742c2670cf4cac646384\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/c5/df/d9bf8223023d31343b65f1cc57d2dc005610ebbcd2b4a5d1e7\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612902 sha256=ae7f430e0be05dd142b3d83bbc65089b41e2f46c08f8d70144d1aea52d0336be\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/9e/42/3224f85730f92fa2925f0b4fb6ef7f9c5431a64dfc77b95b39\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185259 sha256=bd281e839b8c1b2df8e9e427d78f6a08644ff15246b724761282b706c6292254\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n",
            "Successfully built jukebox fire librosa mpi4py\n",
            "Installing collected packages: llvmlite, numba, unidecode, tqdm, mpi4py, librosa, fire, jukebox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.1.3 jukebox-1.0 librosa-0.7.2 llvmlite-0.31.0 mpi4py-3.1.3 numba-0.48.0 tqdm-4.45.0 unidecode-1.1.1\n",
            "Using cuda True\n",
            "18:17:18\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Creating cond. autoregress with prior bins [79, 2048], \n",
            "dims [384, 6144], \n",
            "shift [ 0 79]\n",
            "input shape 6528\n",
            "input bins 2127\n",
            "Self copy is False\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v3_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v3_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:786432\n",
            "Restored from /content/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "mode is now ancestral\n",
            "ancestral\n",
            "None\n",
            "44100\n",
            "128\n",
            "aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.55\n",
            "Sampling level 2\n",
            "Sampling 6144 tokens for [0,6144]. Conditioning on 0 tokens\n",
            "Ancestral sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "24/24 [00:03<00:00,  7.65it/s]\n",
            "6144/6144 [08:14<00:00, 12.43it/s]\n",
            "Step \u001b[34m1\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[33m???\u001b[0m\n",
            "Sampling 6144 tokens for [768,6912]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.96it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m2\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m111.80113199999998\u001b[0m\n",
            "Sampling 6144 tokens for [1536,7680]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.98it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m3\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m109.04045386666667\u001b[0m\n",
            "Sampling 6144 tokens for [2304,8448]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.96it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m4\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m106.86932688333333\u001b[0m\n",
            "Sampling 6144 tokens for [3072,9216]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.94it/s]\n",
            "768/768 [01:11<00:00, 10.71it/s]\n",
            "Step \u001b[34m5\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m104.8104134\u001b[0m\n",
            "Sampling 6144 tokens for [3840,9984]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.96it/s]\n",
            "768/768 [01:11<00:00, 10.73it/s]\n",
            "Step \u001b[34m6\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m101.57349156666668\u001b[0m\n",
            "Sampling 6144 tokens for [4608,10752]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.73it/s]\n",
            "Step \u001b[34m7\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m99.62103133333332\u001b[0m\n",
            "Sampling 6144 tokens for [5376,11520]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.96it/s]\n",
            "768/768 [01:11<00:00, 10.72it/s]\n",
            "Step \u001b[34m8\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m97.17853015\u001b[0m\n",
            "Sampling 6144 tokens for [6144,12288]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.96it/s]\n",
            "768/768 [01:11<00:00, 10.73it/s]\n",
            "Step \u001b[34m9\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m95.33352409999999\u001b[0m\n",
            "Sampling 6144 tokens for [6912,13056]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.98it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m10\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m92.63659783333334\u001b[0m\n",
            "Sampling 6144 tokens for [7680,13824]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.72it/s]\n",
            "Step \u001b[34m11\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m90.77695500000002\u001b[0m\n",
            "Sampling 6144 tokens for [8448,14592]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.99it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m12\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m87.79657833333333\u001b[0m\n",
            "Sampling 6144 tokens for [9216,15360]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.98it/s]\n",
            "768/768 [01:11<00:00, 10.72it/s]\n",
            "Step \u001b[34m13\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m85.22923479999999\u001b[0m\n",
            "Sampling 6144 tokens for [9984,16128]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.73it/s]\n",
            "Step \u001b[34m14\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m83.1971635\u001b[0m\n",
            "Sampling 6144 tokens for [10752,16896]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m15\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m80.72322933333334\u001b[0m\n",
            "Sampling 6144 tokens for [11520,17664]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.99it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m16\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m77.89559203333333\u001b[0m\n",
            "Sampling 6144 tokens for [12288,18432]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.72it/s]\n",
            "Step \u001b[34m17\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m75.595832\u001b[0m\n",
            "Sampling 6144 tokens for [13056,19200]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m18\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m73.84276089999999\u001b[0m\n",
            "Sampling 6144 tokens for [13824,19968]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.99it/s]\n",
            "768/768 [01:11<00:00, 10.73it/s]\n",
            "Step \u001b[34m19\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m71.18731526666667\u001b[0m\n",
            "Sampling 6144 tokens for [14592,20736]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m20\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m68.6025333\u001b[0m\n",
            "Sampling 6144 tokens for [15360,21504]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m21\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m65.99528823333333\u001b[0m\n",
            "Sampling 6144 tokens for [16128,22272]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.98it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m22\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m63.15960333333332\u001b[0m\n",
            "Sampling 6144 tokens for [16896,23040]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.02it/s]\n",
            "768/768 [01:11<00:00, 10.77it/s]\n",
            "Step \u001b[34m23\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m60.90101519999999\u001b[0m\n",
            "Sampling 6144 tokens for [17664,23808]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.77it/s]\n",
            "Step \u001b[34m24\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m58.354481050000004\u001b[0m\n",
            "Sampling 6144 tokens for [18432,24576]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.02it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m25\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m55.96226276666667\u001b[0m\n",
            "Sampling 6144 tokens for [19200,25344]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m26\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m53.647902\u001b[0m\n",
            "Sampling 6144 tokens for [19968,26112]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m27\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m51.092064666666666\u001b[0m\n",
            "Sampling 6144 tokens for [20736,26880]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m28\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m48.54735378333333\u001b[0m\n",
            "Sampling 6144 tokens for [21504,27648]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.99it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m29\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m45.8348469\u001b[0m\n",
            "Sampling 6144 tokens for [22272,28416]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.98it/s]\n",
            "768/768 [01:11<00:00, 10.74it/s]\n",
            "Step \u001b[34m30\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m43.57164118333333\u001b[0m\n",
            "Sampling 6144 tokens for [23040,29184]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.98it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m31\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m41.010841600000006\u001b[0m\n",
            "Sampling 6144 tokens for [23808,29952]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m32\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m38.46757875\u001b[0m\n",
            "Sampling 6144 tokens for [24576,30720]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.99it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m33\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m36.05464893333333\u001b[0m\n",
            "Sampling 6144 tokens for [25344,31488]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m34\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m33.47528513333333\u001b[0m\n",
            "Sampling 6144 tokens for [26112,32256]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m35\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m30.920099599999997\u001b[0m\n",
            "Sampling 6144 tokens for [26880,33024]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.99it/s]\n",
            "768/768 [01:11<00:00, 10.77it/s]\n",
            "Step \u001b[34m36\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m28.426906933333335\u001b[0m\n",
            "Sampling 6144 tokens for [27648,33792]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m37\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m26.4711055\u001b[0m\n",
            "Sampling 6144 tokens for [28416,34560]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.96it/s]\n",
            "768/768 [01:11<00:00, 10.77it/s]\n",
            "Step \u001b[34m38\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m23.422701599999996\u001b[0m\n",
            "Sampling 6144 tokens for [29184,35328]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  6.97it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m39\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m20.92381333333333\u001b[0m\n",
            "Sampling 6144 tokens for [29952,36096]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.00it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m40\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m18.1293406\u001b[0m\n",
            "Sampling 6144 tokens for [30720,36864]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m41\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m15.5996242\u001b[0m\n",
            "Sampling 6144 tokens for [31488,37632]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.76it/s]\n",
            "Step \u001b[34m42\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m13.083355083333332\u001b[0m\n",
            "Sampling 6144 tokens for [32256,38400]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "360/360 [00:51<00:00,  7.01it/s]\n",
            "768/768 [01:11<00:00, 10.75it/s]\n",
            "Step \u001b[34m43\u001b[0m/\u001b[31m47\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m10.422421066666667\u001b[0m\n",
            "Sampling 6144 tokens for [33024,39168]. Conditioning on 5376 tokens\n",
            "Primed sampling 8 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "248/360 [00:29<00:18,  6.06it/s]"
          ]
        }
      ],
      "source": [
        "#@title Start sampling\n",
        "\n",
        "################\n",
        "#Start Sampling#\n",
        "################\n",
        "\n",
        "if lemode=='ancestral':\n",
        "  leprompt_length_in_seconds=None  \n",
        "  leaudio_file = None\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "codes_file=None\n",
        "\n",
        "!pip install git+https://github.com/openai/jukebox.git  # :O\n",
        "\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave start\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "filex = \"/usr/local/lib/python3.7/dist-packages/jukebox/sample.py\"\n",
        "fin = open(filex, \"rt\")\n",
        "data = fin.read()\n",
        "fin.close()\n",
        "\n",
        "newtext = '''import fire\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "from termcolor import colored\n",
        "from datetime import datetime\n",
        "\n",
        "newtosample = True'''\n",
        "data = data.replace('import fire',newtext)\n",
        "\n",
        "newtext = '''starts = get_starts(total_length, prior.n_ctx, hop_length)\n",
        "        counterr = 0\n",
        "        x = None\n",
        "        for start in starts:'''\n",
        "data = data.replace('for start in get_starts(total_length, prior.n_ctx, hop_length):',newtext)\n",
        "\n",
        "newtext = '''global newtosample\n",
        "    newtosample = (new_tokens > 0)\n",
        "    if new_tokens <= 0:'''\n",
        "data = data.replace('if new_tokens <= 0:',newtext)\n",
        "\n",
        "newtext = '''counterr += 1\n",
        "            datea = datetime.now()\t\t\n",
        "            zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)\t\t\t\n",
        "            if newtosample and counterr < len(starts):\n",
        "                del x; x = None; prior.cpu(); empty_cache()\n",
        "                x = prior.decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n",
        "                logdir = f\"{hps.name}/level_{level}\"\n",
        "                if not os.path.exists(logdir):\n",
        "                    os.makedirs(logdir)\n",
        "                t.save(dict(zs=zs, labels=labels, sampling_kwargs=sampling_kwargs, x=x), f\"{logdir}/data.pth.tar\")\n",
        "                save_wav(logdir, x, hps.sr)\n",
        "                del x; prior.cuda(); empty_cache(); x = None\n",
        "            dateb = datetime.now()\n",
        "            timex = ((dateb-datea).total_seconds()/60.0)*(len(starts)-counterr)\n",
        "            print(f\"Step \" + colored(counterr,'blue') + \"/\" + colored( len(starts),'red') + \" ~ New to Sample: \" + str(newtosample) + \" ~ estimated remaining minutes: \" + (colored('???','yellow'), colored(timex,'magenta'))[counterr > 1 and newtosample])'''\n",
        "data = data.replace('zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)',newtext)\n",
        "\n",
        "\n",
        "newtext = \"\"\"lepath=hps.name\n",
        "        if level==2:\n",
        "          for filex in glob(os.path.join(lepath + '/level_2','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-'))\n",
        "        if level==1:\n",
        "          for filex in glob(os.path.join(lepath + '/level_1','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L1-'))\n",
        "        if level==0:\n",
        "          for filex in glob(os.path.join(lepath + '/level_0','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L0-'))\n",
        "        save_html(\"\"\"\n",
        "if leautorename:\n",
        "  data = data.replace('save_html(',newtext)\n",
        "\n",
        "if leexportlyrics == False:\n",
        "  data = data.replace('if alignments is None','#if alignments is None')\n",
        "  data = data.replace('alignments = get_alignment','#alignments = get_alignment')\n",
        "  data = data.replace('save_html(','#save_html(')\n",
        "\n",
        "if leprogress == False:\n",
        "  data = data.replace('print(f\"Step \" +','#print(f\"Step \" +')\n",
        "  \n",
        "fin = open(filex, \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave end\n",
        "\n",
        "###CUSTOM MODEL############ To Sample with Google Drive\n",
        "if not '1b' in lemodel and not '5b' in lemodel:\n",
        "  lemodelpath = '/content/checkpoint_latest.pth.tar' # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"rt\")\n",
        "  data = fin.read();  fin.close()\n",
        "  \n",
        "\n",
        "  data += lemodel + \"\"\"_prior = Hyperparams()   \n",
        "\"\"\" + lemodel + \"\"\"_prior.update(prior_1b_lyrics)\n",
        "\"\"\" + lemodel + \"\"\"_prior.restore_prior='\"\"\" + lemodelpath + \"\"\"'\n",
        "\"\"\" + lemodel + \"\"\"_prior.level=2\n",
        "HPARAMS_REGISTRY['\"\"\" + lemodel + \"\"\"_prior'] = \"\"\" + lemodel + \"\"\"_prior\n",
        "\"\"\"\n",
        "    \n",
        "\n",
        "  #data = data.replace('y_bins=(10,100)','y_bins=(604, 7898)')\n",
        "  data = data.replace('min_duration=60.0','min_duration=24.0')\n",
        "  data = data.replace('max_duration=600.0','max_duration=666.0')\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"wt\")\n",
        "  fin.write(data);  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"rt\")\n",
        "  data = fin.read(); fin.close()  \n",
        "\n",
        "  data = data.replace(\"#'your_model': \",\"'\" +lemodel + \"_model': \")\n",
        "  data = data.replace('(\"you_vqvae_here\", \"your_upsampler_here\", ..., \"you_top_level_prior_here\")','(\"vqvae\",  \"upsampler_level_0\", \"upsampler_level_1\", \"' + lemodel + '_prior\"),')\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"wt\")\n",
        "  fin.write(data); fin.close()  \n",
        "\n",
        "  lemodel = lemodel + \"_model\"\n",
        "###CUSTOM MODEL END############\n",
        "\n",
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "model = lemodel\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = lecount \n",
        "hps.name = lepath\n",
        "\n",
        "chunk_size = lechunk_size\n",
        "max_batch_size = lemax_batch_size\n",
        "\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = lehop\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 786432)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "\n",
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = lemode\n",
        "codes_file=None\n",
        "audio_file = leaudio_file\n",
        "prompt_length_in_seconds=leprompt_length_in_seconds\n",
        "\n",
        "\n",
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [0, 1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = mode if 'continue' in mode else 'upsample'\n",
        "      codes_file = data\n",
        "      print(mode + 'ing from level ' + str(level))\n",
        "      break\n",
        "print('mode is now '+mode)\n",
        "\n",
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))\n",
        "\n",
        "sample_length_in_seconds = lesample_length_in_seconds \n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
        "\n",
        "metas = [dict(artist = leartist,\n",
        "            genre = legenre,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = lelyrics,\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "\n",
        "#----------------------------------------------------------2\n",
        "\n",
        "\n",
        "sampling_temperature = lesampling_temperature\n",
        "lower_batch_size = lelower_batch_size\n",
        "max_batch_size = lemax_batch_size\n",
        "lower_level_chunk_size = lelower_level_chunk_size\n",
        "chunk_size = lechunk_size \n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
        "\n",
        "print(sample_hps.mode)\n",
        "print(sample_hps.prompt_length_in_seconds)\n",
        "print(hps.sr)\n",
        "print(top_prior.raw_to_tokens)\n",
        "print('aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.55')\n",
        "\n",
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  \n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'continue':\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'cutcontinue':\n",
        "  print('-------CUT INIT--------')\n",
        "  lecutlen = (int(lecut*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  print(lecutlen)\n",
        "  data = t.load(codes_file, map_location='cpu')\n",
        "  zabaca = [z.cuda() for z in data['zs']]\n",
        "  print(zabaca)\n",
        "  assert zabaca[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  priorsz = [top_prior] * 3\n",
        "  top_raw_to_tokens = priorsz[-1].raw_to_tokens\n",
        "  assert lecutlen % top_raw_to_tokens == 0, f\"Cut-off duration {lecutlen} not an exact multiple of top_raw_to_tokens\"\n",
        "  assert lecutlen//top_raw_to_tokens <= zabaca[-1].shape[1], f\"Cut-off tokens {lecutlen//priorsz[-1].raw_to_tokens} longer than tokens {zs[-1].shape[1]} in saved codes\"\n",
        "  zabaca = [z[:,:lecutlen//prior.raw_to_tokens] for z, prior in zip(zabaca, priorsz)]\n",
        "  hps.sample_length = lecutlen\n",
        "  print(zabaca)\n",
        "  zs = _sample(zabaca, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  del data\n",
        "  print('-------CUT OK--------')\n",
        "  hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zibica = [z.cuda() for z in data['zs']]\n",
        "  zubu = zibica[:]\n",
        "  if transpose != [0,1,2]:\n",
        "    zubu[2][0] = zibica[:][2][transpose[0]];zubu[2][1] = zibica[:][2][transpose[1]];zubu[2][2] = zibica[:][2][transpose[2]]\n",
        "    zubu[1][0] = zibica[:][1][transpose[0]];zubu[1][1] = zibica[:][1][transpose[1]];zubu[1][2] = zibica[:][1][transpose[2]]\n",
        "    zubu[0][0] = zibica[:][0][transpose[0]];zubu[0][1] = zibica[:][0][transpose[1]];zubu[0][2] = zibica[:][0][transpose[2]]\n",
        "  zubu = _sample(zubu, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  print('-------CONTINUE AFTER CUT OK--------')\n",
        "  zs = zubu\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')\n",
        "\n",
        "\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGS4pnjbmI1"
      },
      "source": [
        "# 2. Upsample 🎉\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq3B_1BdQ0dq"
      },
      "source": [
        "# **IMPORTANT FOR UPSAMPLING TO WORK!**\n",
        "To upsample, please **FACTORY RESET** your runtime!! This is very important!\n",
        "\n",
        "After this, connect your drive to the colab notebook, **DO NOT DOWNLOAD A 1b_finetuned MODEL** and then click he cell where you define your lyrics, genre, sample length, etc...\n",
        "\n",
        "Now, run the cells here\n",
        "\n",
        "\n",
        "If you're still confused, to upsample, run the cells that have a star ( * ) in them and then the rest of the cells below the \"Setup for upsampling\" cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vFVnLXf4RKXA"
      },
      "outputs": [],
      "source": [
        "#@markdown Re-define your parameters to work with upsampling. *\n",
        "\n",
        "lemode = 'upsample'     # 'ancestral','primed','continue','cutcontinue','upsample'\n",
        "lemodel = '1b_lyrics'                          #5b_lyrics or '5b' or '1b_lyrics'\n",
        "\n",
        "lesampling_temperature = .98\n",
        "lehop = [1,1,.125]                 #default [.5,.5,.125], optimized [1,1,0.0625]                   \n",
        "lecut = 70               # used only on cutcontinue\n",
        "transpose = [0,1,2]      # used only on cutcontinue [0,1,2] = default, ex [1,1,1] all samples are copied from item 1\n",
        "\n",
        "leexportlyrics = False\n",
        "leprogress = True\n",
        "leautorename = True\n",
        "\n",
        "lecustommodellyrics = True\n",
        "\n",
        "lechunk_size = 16 \n",
        "lemax_batch_size = 96\n",
        "lelower_batch_size = lecount\n",
        "lelower_level_chunk_size = lechunk_size * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6yHol5Q2RwzG"
      },
      "outputs": [],
      "source": [
        "#@markdown Setup for upsampling. *\n",
        "\n",
        "if lemode=='ancestral':\n",
        "  leprompt_length_in_seconds=None  \n",
        "  leaudio_file = None\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "codes_file=None\n",
        "\n",
        "!pip install git+https://github.com/openai/jukebox.git\n",
        "\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave start\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "filex = \"/usr/local/lib/python3.7/dist-packages/jukebox/sample.py\"\n",
        "fin = open(filex, \"rt\")\n",
        "data = fin.read()\n",
        "fin.close()\n",
        "\n",
        "newtext = '''import fire\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "from termcolor import colored\n",
        "from datetime import datetime\n",
        "\n",
        "newtosample = True'''\n",
        "data = data.replace('import fire',newtext)\n",
        "\n",
        "newtext = '''starts = get_starts(total_length, prior.n_ctx, hop_length)\n",
        "        counterr = 0\n",
        "        x = None\n",
        "        for start in starts:'''\n",
        "data = data.replace('for start in get_starts(total_length, prior.n_ctx, hop_length):',newtext)\n",
        "\n",
        "newtext = '''global newtosample\n",
        "    newtosample = (new_tokens > 0)\n",
        "    if new_tokens <= 0:'''\n",
        "data = data.replace('if new_tokens <= 0:',newtext)\n",
        "\n",
        "newtext = '''counterr += 1\n",
        "            datea = datetime.now()\t\t\n",
        "            zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)\t\t\t\n",
        "            if newtosample and counterr < len(starts):\n",
        "                del x; x = None; prior.cpu(); empty_cache()\n",
        "                x = prior.decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n",
        "                logdir = f\"{hps.name}/level_{level}\"\n",
        "                if not os.path.exists(logdir):\n",
        "                    os.makedirs(logdir)\n",
        "                t.save(dict(zs=zs, labels=labels, sampling_kwargs=sampling_kwargs, x=x), f\"{logdir}/data.pth.tar\")\n",
        "                save_wav(logdir, x, hps.sr)\n",
        "                del x; prior.cuda(); empty_cache(); x = None\n",
        "            dateb = datetime.now()\n",
        "            timex = ((dateb-datea).total_seconds()/60.0)*(len(starts)-counterr)\n",
        "            print(f\"Step \" + colored(counterr,'blue') + \"/\" + colored( len(starts),'red') + \" ~ New to Sample: \" + str(newtosample) + \" ~ estimated remaining minutes: \" + (colored('???','yellow'), colored(timex,'magenta'))[counterr > 1 and newtosample])'''\n",
        "data = data.replace('zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)',newtext)\n",
        "\n",
        "\n",
        "newtext = \"\"\"lepath=hps.name\n",
        "        if level==2:\n",
        "          for filex in glob(os.path.join(lepath + '/level_2','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-'))\n",
        "        if level==1:\n",
        "          for filex in glob(os.path.join(lepath + '/level_1','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L1-'))\n",
        "        if level==0:\n",
        "          for filex in glob(os.path.join(lepath + '/level_0','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L0-'))\n",
        "        save_html(\"\"\"\n",
        "if leautorename:\n",
        "  data = data.replace('save_html(',newtext)\n",
        "\n",
        "if leexportlyrics == False:\n",
        "  data = data.replace('if alignments is None','#if alignments is None')\n",
        "  data = data.replace('alignments = get_alignment','#alignments = get_alignment')\n",
        "  data = data.replace('save_html(','#save_html(')\n",
        "\n",
        "if leprogress == False:\n",
        "  data = data.replace('print(f\"Step \" +','#print(f\"Step \" +')\n",
        "  \n",
        "fin = open(filex, \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave end\n",
        "\n",
        "###CUSTOM MODEL############ To Sample with Google Drive\n",
        "if not '1b' in lemodel and not '5b' in lemodel:\n",
        "  lemodelpath = '/content/gdrive/MyDrive/juke/' + lemodel + '_prior/checkpoint_latest.pth.tar'\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"rt\")\n",
        "  data = fin.read();  fin.close()\n",
        "  \n",
        "  if lecustommodellyrics:\n",
        "    data += lemodel + \"\"\"_prior = Hyperparams()   \n",
        "\"\"\" + lemodel + \"\"\"_prior.update(small_single_enc_dec_prior)\n",
        "\"\"\" + lemodel + \"\"\"_prior.restore_prior='\"\"\" + lemodelpath + \"\"\"'\n",
        "\"\"\" + lemodel + \"\"\"_prior.n_ctx=8192\n",
        "\"\"\" + lemodel + \"\"\"_prior.alignment_layer=47\n",
        "\"\"\" + lemodel + \"\"\"_prioralignment_head=0\n",
        "\"\"\" + lemodel + \"\"\"_prior.l_bins=2048\n",
        "\"\"\" + lemodel + \"\"\"_prior.level=2\n",
        "HPARAMS_REGISTRY['\"\"\" + lemodel + \"\"\"_prior'] = \"\"\" + lemodel + \"\"\"_prior\n",
        "\"\"\"\n",
        "  else:\n",
        "    data += lemodel + \"\"\"_prior = Hyperparams()   \n",
        "\"\"\" + lemodel + \"\"\"_prior.update(small_prior)\n",
        "\"\"\" + lemodel + \"\"\"_prior.restore_prior='\"\"\" + lemodelpath + \"\"\"'\n",
        "\"\"\" + lemodel + \"\"\"_prior.n_ctx=8192\n",
        "\"\"\" + lemodel + \"\"\"_prior.l_bins=2048\n",
        "\"\"\" + lemodel + \"\"\"_prior.level=2\n",
        "\"\"\" + lemodel + \"\"\"_prior.labels=False\n",
        "HPARAMS_REGISTRY['\"\"\" + lemodel + \"\"\"_prior'] = \"\"\" + lemodel + \"\"\"_prior\n",
        "\"\"\"\n",
        "    \n",
        "\n",
        "  data = data.replace('y_bins=(10,100)','y_bins=(604, 7898)')\n",
        "  data = data.replace('min_duration=60.0','min_duration=24.0')\n",
        "  data = data.replace('max_duration=600.0','max_duration=666.0')\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/hparams.py\", \"wt\")\n",
        "  fin.write(data);  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"rt\")\n",
        "  data = fin.read(); fin.close()  \n",
        "\n",
        "  data = data.replace(\"#'your_model': \",\"'\" +lemodel + \"_model': \")\n",
        "  data = data.replace('(\"you_vqvae_here\", \"your_upsampler_here\", ..., \"you_top_level_prior_here\")','(\"vqvae\",  \"upsampler_level_0\", \"upsampler_level_1\", \"' + lemodel + '_prior\"),')\n",
        "\n",
        "  fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"wt\")\n",
        "  fin.write(data); fin.close()  \n",
        "\n",
        "  lemodel = lemodel + \"_model\"\n",
        "\n",
        "fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"rt\")\n",
        "data = fin.read(); fin.close()  \n",
        "\n",
        "data = data.replace(\"dist.barrier()\",\"dist.barrier(); print('1')\")\n",
        "data = data.replace(\"checkpoint = t.load(restore, map_location=t.device('cpu'))\",\"checkpoint = t.load(restore, map_location=t.device('cuda')); print('2')\")\n",
        "\n",
        "fin = open(\"/usr/local/lib/python3.7/dist-packages/jukebox/make_models.py\", \"wt\")\n",
        "fin.write(data); fin.close()  \n",
        "###CUSTOM MODEL END############\n",
        "\n",
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "model = lemodel\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = lecount \n",
        "hps.name = lepath\n",
        "\n",
        "chunk_size = lechunk_size\n",
        "max_batch_size = lemax_batch_size\n",
        "\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = lehop\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "\n",
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = lemode\n",
        "codes_file=None\n",
        "audio_file = leaudio_file\n",
        "prompt_length_in_seconds=leprompt_length_in_seconds\n",
        "\n",
        "\n",
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [0, 1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = mode if 'continue' in mode else 'upsample'\n",
        "      codes_file = data\n",
        "      print(mode + 'ing from level ' + str(level))\n",
        "      break\n",
        "print('mode is now '+mode)\n",
        "\n",
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))\n",
        "\n",
        "sample_length_in_seconds = lesample_length_in_seconds \n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
        "\n",
        "metas = [dict(artist = leartist,\n",
        "            genre = legenre,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = lelyrics,\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "\n",
        "#----------------------------------------------------------2\n",
        "\n",
        "\n",
        "sampling_temperature = lesampling_temperature\n",
        "lower_batch_size = lelower_batch_size\n",
        "max_batch_size = lemax_batch_size\n",
        "lower_level_chunk_size = lelower_level_chunk_size\n",
        "chunk_size = lechunk_size \n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
        "\n",
        "print(sample_hps.mode)\n",
        "print(sample_hps.prompt_length_in_seconds)\n",
        "print(hps.sr)\n",
        "print(top_prior.raw_to_tokens)\n",
        "print('aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.55')\n",
        "\n",
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  \n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'continue':\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'cutcontinue':\n",
        "  print('-------CUT INIT--------')\n",
        "  lecutlen = (int(lecut*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  print(lecutlen)\n",
        "  data = t.load(codes_file, map_location='cpu')\n",
        "  zabaca = [z.cuda() for z in data['zs']]\n",
        "  print(zabaca)\n",
        "  assert zabaca[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  priorsz = [top_prior] * 3\n",
        "  top_raw_to_tokens = priorsz[-1].raw_to_tokens\n",
        "  assert lecutlen % top_raw_to_tokens == 0, f\"Cut-off duration {lecutlen} not an exact multiple of top_raw_to_tokens\"\n",
        "  assert lecutlen//top_raw_to_tokens <= zabaca[-1].shape[1], f\"Cut-off tokens {lecutlen//priorsz[-1].raw_to_tokens} longer than tokens {zs[-1].shape[1]} in saved codes\"\n",
        "  zabaca = [z[:,:lecutlen//prior.raw_to_tokens] for z, prior in zip(zabaca, priorsz)]\n",
        "  hps.sample_length = lecutlen\n",
        "  print(zabaca)\n",
        "  zs = _sample(zabaca, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  del data\n",
        "  print('-------CUT OK--------')\n",
        "  hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zibica = [z.cuda() for z in data['zs']]\n",
        "  zubu = zibica[:]\n",
        "  if transpose != [0,1,2]:\n",
        "    zubu[2][0] = zibica[:][2][transpose[0]];zubu[2][1] = zibica[:][2][transpose[1]];zubu[2][2] = zibica[:][2][transpose[2]]\n",
        "    zubu[1][0] = zibica[:][1][transpose[0]];zubu[1][1] = zibica[:][1][transpose[1]];zubu[1][2] = zibica[:][1][transpose[2]]\n",
        "    zubu[0][0] = zibica[:][0][transpose[0]];zubu[0][1] = zibica[:][0][transpose[1]];zubu[0][2] = zibica[:][0][transpose[2]]\n",
        "  zubu = _sample(zubu, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  print('-------CONTINUE AFTER CUT OK--------')\n",
        "  zs = zubu\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')\n",
        "\n",
        "\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPB7e2HsR-mg"
      },
      "outputs": [],
      "source": [
        "os.remove('/root/.cache/jukebox/models/1b_lyrics/prior_level_2.pth.tar')\n",
        "!wget -O /root/.cache/jukebox/models/5b/prior_level_0.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_0.pth.tar\n",
        "!wget -O /root/.cache/jukebox/models/5b/prior_level_1.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_1.pth.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VK_xmWrrR_ra"
      },
      "outputs": [],
      "source": [
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "del top_prior\n",
        "empty_cache()\n",
        "top_prior=None\n",
        "\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n",
        "\n",
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2XtTS4tVqB8"
      },
      "source": [
        "<font size=60> 🕴️‍♀️ </font>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "1b_Finetuned v1.4.20 (Community models) for Free users",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}